{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture. If you need help at any point, you can consult our solution notebook here.\n",
    "\n",
    "Imagine that you want to compete on Jeopardy, and you're looking for any way to win. In this project, you'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win.\n",
    "\n",
    "The dataset is named jeopardy.csv, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which you can download here (https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/). Here's the beginning of the file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "- Show Number - the Jeopardy episode number\n",
    "- Air Date - the date the episode aired\n",
    "- Round - the round of Jeopardy\n",
    "- Category - the category of the question\n",
    "- Value - the number of dollars the correct answer is worth\n",
    "- Question - the text of the question\n",
    "- Answer - the text of the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeopardy Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      " Air Date      19999 non-null object\n",
      " Round         19999 non-null object\n",
      " Category      19999 non-null object\n",
      " Value         19999 non-null object\n",
      " Question      19999 non-null object\n",
      " Answer        19999 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above we see that there are whitespaces before and after the word which we must remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#in this case we did it this way as it small enough to manually fix it\n",
    "#however if it was too big we would use jeopardy.columns = jeopardy.columns.str.strip() \n",
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>3-LETTER WORDS</td>\n",
       "      <td>$200</td>\n",
       "      <td>In the title of an Aesop fable, this insect sh...</td>\n",
       "      <td>the ant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$400</td>\n",
       "      <td>Built in 312 B.C. to link Rome &amp; the South of ...</td>\n",
       "      <td>the Appian Way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$400</td>\n",
       "      <td>No. 8: 30 steals for the Birmingham Barons; 2,...</td>\n",
       "      <td>Michael Jordan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$400</td>\n",
       "      <td>In the winter of 1971-72, a record 1,122 inche...</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$400</td>\n",
       "      <td>This housewares store was named for the packag...</td>\n",
       "      <td>Crate &amp; Barrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$400</td>\n",
       "      <td>\"And away we go\"</td>\n",
       "      <td>Jackie Gleason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>3-LETTER WORDS</td>\n",
       "      <td>$400</td>\n",
       "      <td>Cows regurgitate this from the first stomach t...</td>\n",
       "      <td>the cud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$600</td>\n",
       "      <td>In 1000 Rajaraja I of the Cholas battled to ta...</td>\n",
       "      <td>Ceylon (or Sri Lanka)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$600</td>\n",
       "      <td>No. 1: Lettered in hoops, football &amp; lacrosse ...</td>\n",
       "      <td>Jim Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$600</td>\n",
       "      <td>On June 28, 1994 the nat'l weather service beg...</td>\n",
       "      <td>the UV index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$600</td>\n",
       "      <td>This company's Accutron watch, introduced in 1...</td>\n",
       "      <td>Bulova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$600</td>\n",
       "      <td>Outlaw: \"Murdered by a traitor and a coward wh...</td>\n",
       "      <td>Jesse James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>3-LETTER WORDS</td>\n",
       "      <td>$600</td>\n",
       "      <td>A small demon, or a mischievous child (who mig...</td>\n",
       "      <td>imp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$800</td>\n",
       "      <td>Karl led the first of these Marxist organizati...</td>\n",
       "      <td>the International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$800</td>\n",
       "      <td>No. 10: FB/LB for Columbia U. in the 1920s; MV...</td>\n",
       "      <td>(Lou) Gehrig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$800</td>\n",
       "      <td>Africa's lowest temperature was 11 degrees bel...</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$800</td>\n",
       "      <td>Edward Teller &amp; this man partnered in 1898 to ...</td>\n",
       "      <td>(Paul) Bonwit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$2,000</td>\n",
       "      <td>1939 Oscar winner: \"...you are a credit to you...</td>\n",
       "      <td>Hattie McDaniel (for her role in Gone with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>3-LETTER WORDS</td>\n",
       "      <td>$800</td>\n",
       "      <td>In geologic time one of these, shorter than an...</td>\n",
       "      <td>era</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$1000</td>\n",
       "      <td>This Asian political party was founded in 1885...</td>\n",
       "      <td>the Congress Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$1000</td>\n",
       "      <td>No. 5: Only center to lead the NBA in assists;...</td>\n",
       "      <td>(Wilt) Chamberlain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$1000</td>\n",
       "      <td>The Kirschner brothers, Don &amp; Bill, named this...</td>\n",
       "      <td>K2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$1000</td>\n",
       "      <td>Revolutionary War hero: \"His spirit is in Verm...</td>\n",
       "      <td>Ethan Allen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>3-LETTER WORDS</td>\n",
       "      <td>$1000</td>\n",
       "      <td>A single layer of paper, or to perform one's c...</td>\n",
       "      <td>ply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>DR. SEUSS AT THE MULTIPLEX</td>\n",
       "      <td>$400</td>\n",
       "      <td>&lt;a href=\"http://www.j-archive.com/media/2004-1...</td>\n",
       "      <td>Horton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19969</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>AMERICAN HISTORY</td>\n",
       "      <td>$1200</td>\n",
       "      <td>In 1960 the last of these locomotives was reti...</td>\n",
       "      <td>steam engines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>MIND YOUR SHAKESPEARE \"P\"s &amp; \"Q\"s</td>\n",
       "      <td>$1200</td>\n",
       "      <td>Kate: \"if I be waspish, best beware my sting\";...</td>\n",
       "      <td>Petruchio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ALMA MATERS</td>\n",
       "      <td>$1,500</td>\n",
       "      <td>This private college in Northern California bo...</td>\n",
       "      <td>Stanford University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ACTRESSES</td>\n",
       "      <td>$1200</td>\n",
       "      <td>She voiced Princess Pea in \"The Tale of Desper...</td>\n",
       "      <td>Emma Watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>2-LETTER WORDS</td>\n",
       "      <td>$1200</td>\n",
       "      <td>It's the name of the long-awaited new White Ho...</td>\n",
       "      <td>Bo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ANGELS &amp; DEMONS</td>\n",
       "      <td>$1200</td>\n",
       "      <td>Langdon in \"Angels &amp; Demons\" is looking for &lt;a...</td>\n",
       "      <td>an antimatter bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>AMERICAN HISTORY</td>\n",
       "      <td>$1600</td>\n",
       "      <td>In the 1600s most of New York State was occupi...</td>\n",
       "      <td>the Iroquois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>MIND YOUR SHAKESPEARE \"P\"s &amp; \"Q\"s</td>\n",
       "      <td>$1600</td>\n",
       "      <td>Marina's dad (need a hint? he rules Tyre)</td>\n",
       "      <td>Pericles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ALMA MATERS</td>\n",
       "      <td>$1600</td>\n",
       "      <td>Presidential kids are welcome at this New Orle...</td>\n",
       "      <td>Tulane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ACTRESSES</td>\n",
       "      <td>$1600</td>\n",
       "      <td>She didn't vamp it up &amp; did a bella job as Em ...</td>\n",
       "      <td>Kristen Stewart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>2-LETTER WORDS</td>\n",
       "      <td>$1600</td>\n",
       "      <td>Third syllable intoned by the giant who smells...</td>\n",
       "      <td>fo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ANGELS &amp; DEMONS</td>\n",
       "      <td>$1600</td>\n",
       "      <td>Much of \"Angels &amp; Demons\" takes place at one o...</td>\n",
       "      <td>a conclave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>AMERICAN HISTORY</td>\n",
       "      <td>$1,200</td>\n",
       "      <td>In 1899 Secretary of State John Hay proclaimed...</td>\n",
       "      <td>open-door policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>MIND YOUR SHAKESPEARE \"P\"s &amp; \"Q\"s</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Fruity surname of Peter in \"A Midsummer Night'...</td>\n",
       "      <td>Quince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ALMA MATERS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Quincy Jones, Kevin Eubanks &amp; Branford Marsali...</td>\n",
       "      <td>Berklee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ACTRESSES</td>\n",
       "      <td>$2000</td>\n",
       "      <td>In 2009 she returned to being \"Fast &amp; Furious\"...</td>\n",
       "      <td>Michelle Rodriguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>2-LETTER WORDS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>The book of Genesis says this ancient city \"of...</td>\n",
       "      <td>Ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ANGELS &amp; DEMONS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>\"Habakkuk and the Angel\" is one of a series of...</td>\n",
       "      <td>Bernini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>SCIENCE TERMS</td>\n",
       "      <td>None</td>\n",
       "      <td>In medieval England, it meant the smallest uni...</td>\n",
       "      <td>atom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$100</td>\n",
       "      <td>This Texas city is the largest in the U.S. to ...</td>\n",
       "      <td>Houston (Lee Brown)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$100</td>\n",
       "      <td>...&amp; the Crickets</td>\n",
       "      <td>Buddy Holly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$100</td>\n",
       "      <td>In the 990s this son of Erik the Red brought C...</td>\n",
       "      <td>Leif Ericson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$100</td>\n",
       "      <td>Concerning a failed Windows 98 demonstration, ...</td>\n",
       "      <td>Bill Gates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$100</td>\n",
       "      <td>This llama product is used to make hats, blank...</td>\n",
       "      <td>Wool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>DING DONG</td>\n",
       "      <td>$100</td>\n",
       "      <td>In 1967 this company introduced its chocolate-...</td>\n",
       "      <td>Hostess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number    Air Date             Round  \\\n",
       "0             4680  2004-12-31         Jeopardy!   \n",
       "1             4680  2004-12-31         Jeopardy!   \n",
       "2             4680  2004-12-31         Jeopardy!   \n",
       "3             4680  2004-12-31         Jeopardy!   \n",
       "4             4680  2004-12-31         Jeopardy!   \n",
       "5             4680  2004-12-31         Jeopardy!   \n",
       "6             4680  2004-12-31         Jeopardy!   \n",
       "7             4680  2004-12-31         Jeopardy!   \n",
       "8             4680  2004-12-31         Jeopardy!   \n",
       "9             4680  2004-12-31         Jeopardy!   \n",
       "10            4680  2004-12-31         Jeopardy!   \n",
       "11            4680  2004-12-31         Jeopardy!   \n",
       "12            4680  2004-12-31         Jeopardy!   \n",
       "13            4680  2004-12-31         Jeopardy!   \n",
       "14            4680  2004-12-31         Jeopardy!   \n",
       "15            4680  2004-12-31         Jeopardy!   \n",
       "16            4680  2004-12-31         Jeopardy!   \n",
       "17            4680  2004-12-31         Jeopardy!   \n",
       "18            4680  2004-12-31         Jeopardy!   \n",
       "19            4680  2004-12-31         Jeopardy!   \n",
       "20            4680  2004-12-31         Jeopardy!   \n",
       "21            4680  2004-12-31         Jeopardy!   \n",
       "22            4680  2004-12-31         Jeopardy!   \n",
       "23            4680  2004-12-31         Jeopardy!   \n",
       "24            4680  2004-12-31         Jeopardy!   \n",
       "25            4680  2004-12-31         Jeopardy!   \n",
       "26            4680  2004-12-31         Jeopardy!   \n",
       "27            4680  2004-12-31         Jeopardy!   \n",
       "28            4680  2004-12-31         Jeopardy!   \n",
       "29            4680  2004-12-31  Double Jeopardy!   \n",
       "...            ...         ...               ...   \n",
       "19969         5694  2009-05-14  Double Jeopardy!   \n",
       "19970         5694  2009-05-14  Double Jeopardy!   \n",
       "19971         5694  2009-05-14  Double Jeopardy!   \n",
       "19972         5694  2009-05-14  Double Jeopardy!   \n",
       "19973         5694  2009-05-14  Double Jeopardy!   \n",
       "19974         5694  2009-05-14  Double Jeopardy!   \n",
       "19975         5694  2009-05-14  Double Jeopardy!   \n",
       "19976         5694  2009-05-14  Double Jeopardy!   \n",
       "19977         5694  2009-05-14  Double Jeopardy!   \n",
       "19978         5694  2009-05-14  Double Jeopardy!   \n",
       "19979         5694  2009-05-14  Double Jeopardy!   \n",
       "19980         5694  2009-05-14  Double Jeopardy!   \n",
       "19981         5694  2009-05-14  Double Jeopardy!   \n",
       "19982         5694  2009-05-14  Double Jeopardy!   \n",
       "19983         5694  2009-05-14  Double Jeopardy!   \n",
       "19984         5694  2009-05-14  Double Jeopardy!   \n",
       "19985         5694  2009-05-14  Double Jeopardy!   \n",
       "19986         5694  2009-05-14  Double Jeopardy!   \n",
       "19987         5694  2009-05-14   Final Jeopardy!   \n",
       "19988         3582  2000-03-14         Jeopardy!   \n",
       "19989         3582  2000-03-14         Jeopardy!   \n",
       "19990         3582  2000-03-14         Jeopardy!   \n",
       "19991         3582  2000-03-14         Jeopardy!   \n",
       "19992         3582  2000-03-14         Jeopardy!   \n",
       "19993         3582  2000-03-14         Jeopardy!   \n",
       "19994         3582  2000-03-14         Jeopardy!   \n",
       "19995         3582  2000-03-14         Jeopardy!   \n",
       "19996         3582  2000-03-14         Jeopardy!   \n",
       "19997         3582  2000-03-14         Jeopardy!   \n",
       "19998         3582  2000-03-14         Jeopardy!   \n",
       "\n",
       "                                Category   Value  \\\n",
       "0                                HISTORY    $200   \n",
       "1        ESPN's TOP 10 ALL-TIME ATHLETES    $200   \n",
       "2            EVERYBODY TALKS ABOUT IT...    $200   \n",
       "3                       THE COMPANY LINE    $200   \n",
       "4                    EPITAPHS & TRIBUTES    $200   \n",
       "5                         3-LETTER WORDS    $200   \n",
       "6                                HISTORY    $400   \n",
       "7        ESPN's TOP 10 ALL-TIME ATHLETES    $400   \n",
       "8            EVERYBODY TALKS ABOUT IT...    $400   \n",
       "9                       THE COMPANY LINE    $400   \n",
       "10                   EPITAPHS & TRIBUTES    $400   \n",
       "11                        3-LETTER WORDS    $400   \n",
       "12                               HISTORY    $600   \n",
       "13       ESPN's TOP 10 ALL-TIME ATHLETES    $600   \n",
       "14           EVERYBODY TALKS ABOUT IT...    $600   \n",
       "15                      THE COMPANY LINE    $600   \n",
       "16                   EPITAPHS & TRIBUTES    $600   \n",
       "17                        3-LETTER WORDS    $600   \n",
       "18                               HISTORY    $800   \n",
       "19       ESPN's TOP 10 ALL-TIME ATHLETES    $800   \n",
       "20           EVERYBODY TALKS ABOUT IT...    $800   \n",
       "21                      THE COMPANY LINE    $800   \n",
       "22                   EPITAPHS & TRIBUTES  $2,000   \n",
       "23                        3-LETTER WORDS    $800   \n",
       "24                               HISTORY   $1000   \n",
       "25       ESPN's TOP 10 ALL-TIME ATHLETES   $1000   \n",
       "26                      THE COMPANY LINE   $1000   \n",
       "27                   EPITAPHS & TRIBUTES   $1000   \n",
       "28                        3-LETTER WORDS   $1000   \n",
       "29            DR. SEUSS AT THE MULTIPLEX    $400   \n",
       "...                                  ...     ...   \n",
       "19969                   AMERICAN HISTORY   $1200   \n",
       "19970  MIND YOUR SHAKESPEARE \"P\"s & \"Q\"s   $1200   \n",
       "19971                        ALMA MATERS  $1,500   \n",
       "19972                          ACTRESSES   $1200   \n",
       "19973                     2-LETTER WORDS   $1200   \n",
       "19974                    ANGELS & DEMONS   $1200   \n",
       "19975                   AMERICAN HISTORY   $1600   \n",
       "19976  MIND YOUR SHAKESPEARE \"P\"s & \"Q\"s   $1600   \n",
       "19977                        ALMA MATERS   $1600   \n",
       "19978                          ACTRESSES   $1600   \n",
       "19979                     2-LETTER WORDS   $1600   \n",
       "19980                    ANGELS & DEMONS   $1600   \n",
       "19981                   AMERICAN HISTORY  $1,200   \n",
       "19982  MIND YOUR SHAKESPEARE \"P\"s & \"Q\"s   $2000   \n",
       "19983                        ALMA MATERS   $2000   \n",
       "19984                          ACTRESSES   $2000   \n",
       "19985                     2-LETTER WORDS   $2000   \n",
       "19986                    ANGELS & DEMONS   $2000   \n",
       "19987                      SCIENCE TERMS    None   \n",
       "19988                     U.S. GEOGRAPHY    $100   \n",
       "19989                 POP MUSIC PAIRINGS    $100   \n",
       "19990                    HISTORIC PEOPLE    $100   \n",
       "19991                    1998 QUOTATIONS    $100   \n",
       "19992                         LLAMA-RAMA    $100   \n",
       "19993                          DING DONG    $100   \n",
       "19994                     U.S. GEOGRAPHY    $200   \n",
       "19995                 POP MUSIC PAIRINGS    $200   \n",
       "19996                    HISTORIC PEOPLE    $200   \n",
       "19997                    1998 QUOTATIONS    $200   \n",
       "19998                         LLAMA-RAMA    $200   \n",
       "\n",
       "                                                Question  \\\n",
       "0      For the last 8 years of his life, Galileo was ...   \n",
       "1      No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2      The city of Yuma in this state has a record av...   \n",
       "3      In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4      Signer of the Dec. of Indep., framer of the Co...   \n",
       "5      In the title of an Aesop fable, this insect sh...   \n",
       "6      Built in 312 B.C. to link Rome & the South of ...   \n",
       "7      No. 8: 30 steals for the Birmingham Barons; 2,...   \n",
       "8      In the winter of 1971-72, a record 1,122 inche...   \n",
       "9      This housewares store was named for the packag...   \n",
       "10                                      \"And away we go\"   \n",
       "11     Cows regurgitate this from the first stomach t...   \n",
       "12     In 1000 Rajaraja I of the Cholas battled to ta...   \n",
       "13     No. 1: Lettered in hoops, football & lacrosse ...   \n",
       "14     On June 28, 1994 the nat'l weather service beg...   \n",
       "15     This company's Accutron watch, introduced in 1...   \n",
       "16     Outlaw: \"Murdered by a traitor and a coward wh...   \n",
       "17     A small demon, or a mischievous child (who mig...   \n",
       "18     Karl led the first of these Marxist organizati...   \n",
       "19     No. 10: FB/LB for Columbia U. in the 1920s; MV...   \n",
       "20     Africa's lowest temperature was 11 degrees bel...   \n",
       "21     Edward Teller & this man partnered in 1898 to ...   \n",
       "22     1939 Oscar winner: \"...you are a credit to you...   \n",
       "23     In geologic time one of these, shorter than an...   \n",
       "24     This Asian political party was founded in 1885...   \n",
       "25     No. 5: Only center to lead the NBA in assists;...   \n",
       "26     The Kirschner brothers, Don & Bill, named this...   \n",
       "27     Revolutionary War hero: \"His spirit is in Verm...   \n",
       "28     A single layer of paper, or to perform one's c...   \n",
       "29     <a href=\"http://www.j-archive.com/media/2004-1...   \n",
       "...                                                  ...   \n",
       "19969  In 1960 the last of these locomotives was reti...   \n",
       "19970  Kate: \"if I be waspish, best beware my sting\";...   \n",
       "19971  This private college in Northern California bo...   \n",
       "19972  She voiced Princess Pea in \"The Tale of Desper...   \n",
       "19973  It's the name of the long-awaited new White Ho...   \n",
       "19974  Langdon in \"Angels & Demons\" is looking for <a...   \n",
       "19975  In the 1600s most of New York State was occupi...   \n",
       "19976          Marina's dad (need a hint? he rules Tyre)   \n",
       "19977  Presidential kids are welcome at this New Orle...   \n",
       "19978  She didn't vamp it up & did a bella job as Em ...   \n",
       "19979  Third syllable intoned by the giant who smells...   \n",
       "19980  Much of \"Angels & Demons\" takes place at one o...   \n",
       "19981  In 1899 Secretary of State John Hay proclaimed...   \n",
       "19982  Fruity surname of Peter in \"A Midsummer Night'...   \n",
       "19983  Quincy Jones, Kevin Eubanks & Branford Marsali...   \n",
       "19984  In 2009 she returned to being \"Fast & Furious\"...   \n",
       "19985  The book of Genesis says this ancient city \"of...   \n",
       "19986  \"Habakkuk and the Angel\" is one of a series of...   \n",
       "19987  In medieval England, it meant the smallest uni...   \n",
       "19988  This Texas city is the largest in the U.S. to ...   \n",
       "19989                                  ...& the Crickets   \n",
       "19990  In the 990s this son of Erik the Red brought C...   \n",
       "19991  Concerning a failed Windows 98 demonstration, ...   \n",
       "19992  This llama product is used to make hats, blank...   \n",
       "19993  In 1967 this company introduced its chocolate-...   \n",
       "19994  Of 8, 12 or 18, the number of U.S. states that...   \n",
       "19995                      ...& the New Power Generation   \n",
       "19996  In 1589 he was appointed professor of mathemat...   \n",
       "19997  Before the grand jury she said, \"I'm really so...   \n",
       "19998  Llamas are the heftiest South American members...   \n",
       "\n",
       "                                                  Answer  \n",
       "0                                             Copernicus  \n",
       "1                                             Jim Thorpe  \n",
       "2                                                Arizona  \n",
       "3                                             McDonald's  \n",
       "4                                             John Adams  \n",
       "5                                                the ant  \n",
       "6                                         the Appian Way  \n",
       "7                                         Michael Jordan  \n",
       "8                                             Washington  \n",
       "9                                         Crate & Barrel  \n",
       "10                                        Jackie Gleason  \n",
       "11                                               the cud  \n",
       "12                                 Ceylon (or Sri Lanka)  \n",
       "13                                             Jim Brown  \n",
       "14                                          the UV index  \n",
       "15                                                Bulova  \n",
       "16                                           Jesse James  \n",
       "17                                                   imp  \n",
       "18                                     the International  \n",
       "19                                          (Lou) Gehrig  \n",
       "20                                               Morocco  \n",
       "21                                         (Paul) Bonwit  \n",
       "22     Hattie McDaniel (for her role in Gone with the...  \n",
       "23                                                   era  \n",
       "24                                    the Congress Party  \n",
       "25                                    (Wilt) Chamberlain  \n",
       "26                                                    K2  \n",
       "27                                           Ethan Allen  \n",
       "28                                                   ply  \n",
       "29                                                Horton  \n",
       "...                                                  ...  \n",
       "19969                                      steam engines  \n",
       "19970                                          Petruchio  \n",
       "19971                                Stanford University  \n",
       "19972                                        Emma Watson  \n",
       "19973                                                 Bo  \n",
       "19974                                 an antimatter bomb  \n",
       "19975                                       the Iroquois  \n",
       "19976                                           Pericles  \n",
       "19977                                             Tulane  \n",
       "19978                                    Kristen Stewart  \n",
       "19979                                                 fo  \n",
       "19980                                         a conclave  \n",
       "19981                                   open-door policy  \n",
       "19982                                             Quince  \n",
       "19983                                            Berklee  \n",
       "19984                                 Michelle Rodriguez  \n",
       "19985                                                 Ur  \n",
       "19986                                            Bernini  \n",
       "19987                                               atom  \n",
       "19988                                Houston (Lee Brown)  \n",
       "19989                                        Buddy Holly  \n",
       "19990                                       Leif Ericson  \n",
       "19991                                         Bill Gates  \n",
       "19992                                               Wool  \n",
       "19993                                            Hostess  \n",
       "19994                                                 18  \n",
       "19995                                             Prince  \n",
       "19996                                            Galileo  \n",
       "19997                                    Monica Lewinsky  \n",
       "19998                                             Camels  \n",
       "\n",
       "[19999 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataframe above we can see that words are a mix of upper and lower case. We will need to fix this so that same words aren't treated differently. Fro example Don't and don't won't be considered differnt but the same. \n",
    "\n",
    "To achieve this we will make a function that converts to lowercase and apply to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def lowercase(string):\n",
    "    '''\n",
    "    takes a string and returns all lowercase with it's punctuation removed\n",
    "    '''\n",
    "    \n",
    "    string=string.lower()\n",
    "    res = re.sub(r'[^\\w\\s]', '', string)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question']=jeopardy['Question'].apply(lowercase)\n",
    "jeopardy['clean_answer']=jeopardy['Answer'].apply(lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    for the last 8 years of his life galileo was u...\n",
       "1    no 2 1912 olympian football star at carlisle i...\n",
       "2    the city of yuma in this state has a record av...\n",
       "3    in 1963 live on the art linkletter show this c...\n",
       "4    signer of the dec of indep framer of the const...\n",
       "Name: clean_question, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_question'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    copernicus\n",
       "1    jim thorpe\n",
       "2       arizona\n",
       "3     mcdonalds\n",
       "4    john adams\n",
       "Name: clean_answer, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_answer'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we normalized the text columns, there are also some other columns to normalize.\n",
    "\n",
    "The Value column should be numeric, to allow you to manipulate it easier. We'll need to remove the dollar sign from the beginning of each value and convert the column from text to numeric.\n",
    "\n",
    "The Air Date column should also be a datetime, not a string, to enable you to work it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_values(text):\n",
    "    '''\n",
    "    takes in a string\n",
    "    remove any punctuation in the string\n",
    "    convert the string to an integer\n",
    "    assign 0 instead if the conversion has an error\n",
    "    return the integer.\n",
    "    '''\n",
    "        \n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "Name: clean_value, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_value']=jeopardy['Value'].apply(normalize_values)\n",
    "jeopardy['clean_value'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting air date to datetime\n",
    "\n",
    "jeopardy['Air Date']=pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 10 columns):\n",
      "Show Number       19999 non-null int64\n",
      "Air Date          19999 non-null datetime64[ns]\n",
      "Round             19999 non-null object\n",
      "Category          19999 non-null object\n",
      "Value             19999 non-null object\n",
      "Question          19999 non-null object\n",
      "Answer            19999 non-null object\n",
      "clean_question    19999 non-null object\n",
      "clean_answer      19999 non-null object\n",
      "clean_value       19999 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2), object(7)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers in Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer can be used for a question.\n",
    "- How often questions are repeated.\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question and come back to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    '''\n",
    "    returns the proportion for clean_question\n",
    "    & clean_answer with matching terms\n",
    "    '''\n",
    "    #splitting on whitespaces\n",
    "    split_answer=row['clean_answer'].split()\n",
    "    split_question=row['clean_question'].split()\n",
    "    \n",
    "    #making a varible to increment on\n",
    "    match_count=0\n",
    "    \n",
    "    #removing word (the) as it is the most common in the answer column\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    \n",
    "    #if it is 0 we just say it is 0 as it will prevent division by 0 later on\n",
    "    if len(split_answer)==0:\n",
    "        return 0\n",
    "    \n",
    "    #checking if the word occurs in both split_answer and split_question and if it does increase the count by 1\n",
    "    for i in split_answer:\n",
    "        if i in split_question:\n",
    "            match_count +=1\n",
    "    return match_count/len(split_answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the mean of answer_in_question\n",
    "\n",
    "jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, only 6% of questions have their answers in the questions asked. This is not a whole lot of questions and means we can't hope to win by trying to figure out the answers of questions using the question. So the best strategy will be to actually study for jeopardy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recycled Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to investigate how often new questions are repeats of older ones. We can't completely answer this, because we only have about 10% of the full Jeopardy question dataset, but we can investigate it at least.\n",
    "\n",
    "To do this, you can:\n",
    "\n",
    "- Sort jeopardy in order of ascending air date.\n",
    "- Maintain a set called terms_used that will be empty initially.\n",
    "- Iterate through each row of jeopardy.\n",
    "- Split clean_question into words, remove any word shorter than 6 characters, and check if each word occurs in terms_used.\n",
    " - If it does, increment a counter.\n",
    " - Add each word to terms_used.\n",
    " \n",
    "This allows us to check if the terms in questions have been used previously or not. Only looking at words with six or more characters enables you to filter out words like the and than, which are commonly used, but don't tell you a lot about a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_overlap=[]\n",
    "terms_used=set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values('Air Date')\n",
    "\n",
    "for row in jeopardy.iterrows():\n",
    "    row = row[1]\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [word for word in split_question if len(word) > 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0: # to avoid dividing by 0\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "jeopardy['question_overlap'] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>answer_in_question</th>\n",
       "      <th>question_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>U.S. PRESIDENTS</td>\n",
       "      <td>None</td>\n",
       "      <td>adventurous 26th president he was 1st to ride ...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>adventurous 26th president he was 1st to ride ...</td>\n",
       "      <td>theodore roosevelt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>LABOR UNIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>notorious labor leader missing since 75</td>\n",
       "      <td>Jimmy Hoffa</td>\n",
       "      <td>notorious labor leader missing since 75</td>\n",
       "      <td>jimmy hoffa</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>1789</td>\n",
       "      <td>$200</td>\n",
       "      <td>washington proclaimed nov 26 1789 this first n...</td>\n",
       "      <td>Thanksgiving</td>\n",
       "      <td>washington proclaimed nov 26 1789 this first n...</td>\n",
       "      <td>thanksgiving</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>TOURIST TRAPS</td>\n",
       "      <td>$200</td>\n",
       "      <td>both ferde grofe  the colorado river dug this ...</td>\n",
       "      <td>the Grand Canyon</td>\n",
       "      <td>both ferde grofe  the colorado river dug this ...</td>\n",
       "      <td>the grand canyon</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>$200</td>\n",
       "      <td>depending on the book he could be a jones a sa...</td>\n",
       "      <td>Tom</td>\n",
       "      <td>depending on the book he could be a jones a sa...</td>\n",
       "      <td>tom</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number   Air Date             Round         Category Value  \\\n",
       "19325           10 1984-09-21   Final Jeopardy!  U.S. PRESIDENTS  None   \n",
       "19301           10 1984-09-21  Double Jeopardy!     LABOR UNIONS  $200   \n",
       "19302           10 1984-09-21  Double Jeopardy!             1789  $200   \n",
       "19303           10 1984-09-21  Double Jeopardy!    TOURIST TRAPS  $200   \n",
       "19304           10 1984-09-21  Double Jeopardy!       LITERATURE  $200   \n",
       "\n",
       "                                                Question              Answer  \\\n",
       "19325  adventurous 26th president he was 1st to ride ...  Theodore Roosevelt   \n",
       "19301            notorious labor leader missing since 75         Jimmy Hoffa   \n",
       "19302  washington proclaimed nov 26 1789 this first n...        Thanksgiving   \n",
       "19303  both ferde grofe  the colorado river dug this ...    the Grand Canyon   \n",
       "19304  depending on the book he could be a jones a sa...                 Tom   \n",
       "\n",
       "                                          clean_question        clean_answer  \\\n",
       "19325  adventurous 26th president he was 1st to ride ...  theodore roosevelt   \n",
       "19301            notorious labor leader missing since 75         jimmy hoffa   \n",
       "19302  washington proclaimed nov 26 1789 this first n...        thanksgiving   \n",
       "19303  both ferde grofe  the colorado river dug this ...    the grand canyon   \n",
       "19304  depending on the book he could be a jones a sa...                 tom   \n",
       "\n",
       "       clean_value  answer_in_question  question_overlap  \n",
       "19325            0                 0.0               0.0  \n",
       "19301          200                 0.0               0.0  \n",
       "19302          200                 0.0               0.0  \n",
       "19303          200                 0.0               0.5  \n",
       "19304          200                 0.0               0.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876235590919739"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is about 70% overlap between terms in new questions and terms in old questions. This only looks at a small set of questions, and it doesn't look at phrases, it looks at single terms. This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Value vs High Value Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help us earn more money when you're on Jeopardy.\n",
    "\n",
    "We can actually figure out which terms correspond to high-value questions using a chi-squared test. We will first need to narrow down the questions into two categories:\n",
    "\n",
    "- Low value -- Any row where Value is less than 800.\n",
    "- High value -- Any row where Value is greater than 800.\n",
    "\n",
    "We'll then be able to loop through each of the terms from the last screen, terms_used, and:\n",
    "\n",
    "- Find the number of low value questions the word occurs in.\n",
    "- Find the number of high value questions the word occurs in.\n",
    "- Find the percentage of questions the word occurs in.\n",
    "- Based on the percentage of questions the word occurs in, find expected counts.\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def value_category(row):\n",
    "    '''categorises rows into high or low value\n",
    "    1 = high value, 0 = low vaue'''\n",
    "    \n",
    "    if row['clean_value'] > 800:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "jeopardy['high_value'] = jeopardy.apply(value_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_value(word):\n",
    "    '''counts the value of individual words \n",
    "    in the clean question column'''\n",
    "    \n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for row in jeopardy.iterrows():\n",
    "        row = row[1]\n",
    "        split_question = row['clean_question'].split(' ')\n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 1), (4, 16), (0, 1), (1, 1), (1, 1), (1, 0), (0, 1), (1, 2), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from random import choice\n",
    "comparison_terms = []\n",
    "comparison_terms = [choice(list(terms_used)) for i in range(10)] # picks a random smaple of 10 terms with replacement\n",
    "\n",
    "observed_expected = []\n",
    "for i in comparison_terms:\n",
    "    result = count_value(i)\n",
    "    observed_expected.append(result)\n",
    "    \n",
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Chi-Squared Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've found the observed counts for a few terms,we can compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.7353581241806549, pvalue=0.39115190605378425),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.03188116723440362, pvalue=0.8582887163235293),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our observed_expected list, terms seem to be more frequent in lower value questions, this could be due to the fact that there are more low value questions than high value ones. In cases where there were significant differences(of at least 3) in the term frequencies for low and high value, the pvalues are all less than 0.05 which would mean a strong relationship between those terms and low value words which makes sense as low value questions are more common. Although it was a small sample, there are no strong relationship between terms and high value questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Categories Per Round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeopardy has rounds and here we want to find out the most frequent category in each of the rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jeopardy!           0.495075\n",
       "Double Jeopardy!    0.488124\n",
       "Final Jeopardy!     0.016751\n",
       "Tiebreaker          0.000050\n",
       "Name: Round, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['Round'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy_grp =  jeopardy.groupby(['Round'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD ORIGINS category make up 2.39% of the questions in Final Jeopardy! round\n",
      "LITERATURE category make up 0.36% of the questions in Double Jeopardy! round\n",
      "TELEVISION category make up 0.35% of the questions in Jeopardy! round\n",
      "CHILD'S PLAY category make up 100.0% of the questions in Tiebreaker round\n"
     ]
    }
   ],
   "source": [
    "for i in jeopardy['Round'].unique():\n",
    "    j_round = jeopardy_grp.get_group(i)\n",
    "    top_cat_proportion = j_round['Category'].value_counts(normalize=True)[0] # returns the value for the category with the highest proportion\n",
    "    top_cat_percentage = round(top_cat_proportion * 100,2)\n",
    "    top_cat_name = j_round['Category'].value_counts().index[0] # returns the name of the category with the highest frequency in each round\n",
    "    \n",
    "    print('{} category make up {}% of the questions in {} round'.format(top_cat_name,top_cat_percentage,i)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the questions in our dataset are from the Jeopardy! and Double Jeopardy! rounds, with these round making up nearly 99% of the data, even though we know the top categories for these rounds, these categories make up only a small percentage of the total question. Focusing on just one particular category of question for a specific round isn't a very good strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- While there is no guaranteed strategy to winning Jeopardy as we have found out, it might be worth while to look at past questions while preparing.\n",
    "\n",
    "- There also isn't any significant relationship between any term and high questions, so there is no keyword to look out for to prepare for high value questions.\n",
    "\n",
    "- There isn't a significant question category to focus on for any jeopardy round, it's best to be prepared for as much ccategories as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
